{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Langgraph 实现 Translation Agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e7081a23890617e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (0.2.69)\r\n",
      "Requirement already satisfied: langsmith in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (0.1.147)\r\n",
      "Requirement already satisfied: langchain-openai in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (0.3.3)\r\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from langgraph) (0.3.33)\r\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from langgraph) (2.0.10)\r\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from langgraph) (0.1.51)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from langsmith) (0.28.1)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from langsmith) (3.10.15)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from langsmith) (2.10.6)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from langsmith) (2.32.3)\r\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from langsmith) (1.0.0)\r\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from langchain-openai) (1.61.1)\r\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from langchain-openai) (0.8.0)\r\n",
      "Requirement already satisfied: anyio in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith) (4.8.0)\r\n",
      "Requirement already satisfied: certifi in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith) (2025.1.31)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.7)\r\n",
      "Requirement already satisfied: idna in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.2)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (23.2)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (8.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\r\n",
      "Requirement already satisfied: sniffio in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langsmith) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langsmith) (2.27.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from requests<3,>=2->langsmith) (3.4.1)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from requests<3,>=2->langsmith) (2.3.0)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/chenchen/Desktop/egg/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "! pip install langgraph langsmith langchain-openai"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T08:24:42.761825Z",
     "start_time": "2025-02-06T08:24:41.371273Z"
    }
   },
   "id": "f9ed9e916493d1c2",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM4AAAGwCAIAAABuIs2WAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdcE/f/B/BPdkImGwIiCiLIVHHvKloRUdGqVQT3qKNWbdWq1TqoW+pui6uOqtQ9cdVWbN1axY3iAhkZZEEuySW/P85fyhcCcjG5cPHzfPTRh7lc7t4cLz43cvf5UEwmE4Ag+6M6ugDoYwGjBhEERg0iCIwaRBAYNYggMGoQQeiOLsAuSt5oy1RomRLVIUak3OjocmqFxaHS6BQXPs2FT/MJ5Di6HNujONN1tRcPNHn3NHn3Nf4hHK3G6CKguXoxUT05fkAmhyov0pWpUAoFvHigaRDBbRjBaxzLd3RdNuMkUXvxQPP3Mal3AMs7kN0gnMsVkLu1Rg2mvBzN8xz1ywdlbXq5R7QTOroiGyB91ExGU9bOIj1ibNvb3d2X5ehybEynNV4+JnnzpOzT4b6efuT+6cgdtZJ8ZN+q1wO+9Pepz3Z0LXakkutPZLyN6SwKbSFwdC3WI3HUlDL9yS1vB38d4OhCCHJ2d1FQFLdhJM/RhViJrFHLzy3PPiwZNKOeowshVNbOQg9fVvNuro4uxBqkvK6m1aAnt7392HIGAOgxzKfgefmLBxpHF2INUkbt7O6iITM/upxheo8V3/9bqZLrHV0IbuSL2u0/5K7eTK6A4ehCHKZxC372YYmjq8CNfFH7+5i0bW93R1fhSMHRPKXcUPxK6+hC8CFZ1G5dkHdM8qBSKY4uxMHa93HP+Ufh6CrwIVnUHl5T+gW7ELMuFEXv3LnjqI/XzC/I5elttU5Ljq93MWSKmkKiRw0mNx8mMatbtGhRWlqaoz7+Xg3CuXn3yXQqSqaovXqkIfJyOYIg1n0Qu1Rp9cdrKTiG9zav3K6rsC0yfS0tfatzF9vle8Ds7Ox169a9efNGLBYPGDBg0KBBCxYsOHv2LAAgNjYWAHD06FGxWHz06NH9+/fn5ua6uLi0adNmxowZrq6uAIBz587NmjVr5cqVO3fuvH//fmpqalFRUdWP27Zmviuj8AWZzgzIFDWNEg0Ipdl8sWVlZTNnzmzYsOHcuXNzc3NLSkoAACNHjiwqKsrPz1+4cCEAwMPDAwBw7969wMDA+Ph4mUy2d+9ejUaTnp5uXs6yZcsmTpw4YcKEgIAArVZb9eO25SKglSlRmy/WfsgVNYM97g6SyWQIgnzyySc9e/Y0TwwICBCJRFKpNCYmxjzx22+/pVDenfzS6fStW7ciCMJivWtoBw0alJCQYJ656sdtiyugl6lQk8lkLqmOI1PU6AwKzQ71+vn5RUVFbdmyhcPhJCUlMZnVnnbo9fq9e/eePHmysLCQzWYbjUa5XO7j44O927JlS9sXVyOugGY0mGgMckSNTKcFDCZVrbD9LoNCoaxduzYhISE9PT0pKenWrVsWZzOZTFOnTt26dWtiYuL69evj4+MBAEbjf5cbXFwIugqDKdegqMFEY5DmN0iaQrFdhkZpsMeSeTzerFmzDhw4wOPxpk2bVlZWhk2veNvLrVu3rl27NmvWrCFDhkRERAQHB793sXa9a6ZMaXAh1c3GZIqamy9Dj9jloiV2YcLPz2/w4MFqtbqgoAAAwOFwpFKpud0qLS0FAISGhlZ8WbFVq6TSx22uTGUQNyTTDaG0BQsWOLqG2qIxqNdPy2x+o71er09KSiopKZFIJPv27UMQ5IsvvqDT6SqVKisrq6SkRKlUFhYWhoeHZ2Zmvn37lsvlXrhwISMjQ6/Xx8bGBgYGPn/+/Ny5cwMHDhSJRObFVvp4/fr1bVv2rQulnmKWVwBp0kamqHEF9OtnZY1i+Ey2LRtjjUbz6tWrP/7448KFC56engsWLPD39wcABAcHKxSK06dP37p1SyQSdenSpWHDhseOHTt27JjBYFi8eHFxcfGdO3cSEhIsRq3Sx21+0nAxs7hdoodtN4Vdkewu3CunpCIPBqlvsbcJSQFy46zs01RfRxeCA5mOKwEA0R1Eu5e+rCFqly5dmjdvXtXpLBarum+Ktm3b1qBBA5uWWZlara54ya2iqKiou3fvVp0+bdq0xMTE6hZ45YQ0vC3JntgjWasGAMg+IuEKaE27WL6/XqvVymSyqtN1Ol11F8y8vLzodPv+yRmNxsLCQlwfEQqFXC7X4lsFz8v/OS7tP8XfRtURhHxRQ1Hj0U0F/SaRbEPb0PnfisJbC3wakKyzBdIcVJrRaNS2vT32r3nt6EIc46+DJR5+LNLljJRRAwB412eHtxGc2v7W0YUQ7foZmV5njO4oqsW8dQ75dqBmrx+X5fyj6DmcTGdhH+LGWZnJBFp0d3N0IVYiZauGqdfYpWEE77flr3T2+QqhTjmzqxApN5I3Z+Ru1TCSAuRiZrG4Iadtb9vfE1YX3M0uvXZK1qGfJ9k7wCJ91DA3z8v/OS5tHe/mF8zxJeEhc1WyIl1ejube5dIGTXhtEtyYbNvfE0owJ4ka5s6f8tw7mtJiXZM2AmACXAFd4M4gy49Ho1GUUr1GaUANpuf3NFQqaBDBjeog4olIdpm9Ok4VNUy5Bn3zpEwpM2iUBhMK1Aob33ckkUg0Go3Nvz4XuDFQ1MgV0PmudJ9AtsiToAfDCOOEUbO3w4cP37t3z+LXX1ANSHwGCpELjBpEEBg13FgsFvb4J4QLjBpuCILI5XJHV0E+MGq40Wg087OfUO3BqOGGoqi9++NwSjBquDEYjOpuWoRqAKOGm16v12jI1NtUHQGjhhubzXZ3/6h7SLUOjBpuWq1WKpU6ugrygVGDCAKjhhudTudwnOE+JYLBqOFmMBjKy8nUM2gdAaOGG51OZ7NJ01NG3QGjhpvBYNBqydQJbR0BowYRBEYNNxaLJRSSrL+MugBGDTcEQRQKkg26UxfAqEEEgVHDDX4xZR0YNdzgF1PWgVGDCAKjhhubzbbHQD5OD0YNN61WK5GQbzxrh4NRgwgCo4YbfDjPOjBquMGH86wDowYRBEYNN/gcqHVg1HCDz4FaB0YNNyaTCe/ssAKMGm46nQ7e2WEFGDWIIDBquDEYDILHznYOMGq46fV684jbUO3BqOEG71ezDowabvB+NevAqOEGWzXrwKjhBls168Co4cZkMnk8nqOrIB84REZtJSUl6fV6AEBZWZnBYBAIBNi/z58/7+jSyMFJxi8iQHh4+IkTJ6jUd/sBjUZjMpkaN27s6LpIA+5Aa2v48OG+vv8zzC2LxRo6dKjjKiIZGLXaCgoKat68ecUp9erV69Wrl+MqIhkYNRxSU1M9PT2xfzOZzJSUFEdXRCYwajgEBQW1atUKO5EKDAyETRouMGr4DB061Nvbm8vlDhs2zNG1kAxBZ6BaDSop0OkQIzGrsx8aELeJ7vvmzZvG9To+zyH96AU0GnDzYfJdGQSsy+7X1VCD6cyuwjdPyv1DuHryR83JcF3prx5o3MXMtgnuHmL7PjBh36gh5eiBtfnNe3iIG8AbvOoutUJ/dmdB4lixyNOOzZt9j9X2r3nTcYAPzFkdxxMy+k2qv3/1a6Qctd9a7Bi1+1cUgU14Qg9nG+7eWbVJ9Lx2Wma/5dsxasWvEA4ffvFFGgJ35usndhyPwY5R02mNAjciTm0gmxC6MSkUiv2Wb8eoacuMqB13/ZCNGU1AIdXZb/nwEi5EEBg1iCAwahBBYNQggsCoQQSBUYMIAqMGEQRGDSIIjBpEEBg1iCAwahBB6lbUTp460jepW1FRYc2zPX+em9inS/bli9hLFEXv3btTwwzVGTFq4MJFs2tT2IOHOcR0tfzj2mVJA7rXZk61Wv3k6SP7V2QzdStqTCaLy+WZnyCvDp1O5/H4dNq7O5RWrFq0Oj2thhk+0OmsYxMnDddq7XiDjRVGjx186tQRR1eBQ926n6xb10+7df30vbMFBATu2X3U/FJXpb2pNMMHem97ZjKZ7Hr7jUU6nR3vwrCHOhS1pcsXZGUdBwCczbpCp9Pnfje9nn99Op1+/MQhg17funX7L6fM4vF4p7OOLVv+PQBgxfINsc1bLV2+4I+LZwEAXbrGAgD27D767783K85QXFy0ZdvGq1cvazTqevXqD/l8RG3SbHY661j6j0sBAH2TugEAZn4z/9MevS/+ee77hbMWfb9yX+bOR4/ufz44NXnoqF93/nLhQlZxSZG7u0f3uF7DU8fRaDQAQO8+nad+OTs7+48rV7O5XF7vhP6pKWOwzrPS1y79+++/AABRUU0nfTHDx8e30tpPnT56+PD+53m5HI5LyxZtJk2cIRK5AgAGD0mQy2WHj2QePpLp7e2zd89xbIEZWzacv3Bap0Pq+dcfOHDYJ11qtS8mRh2KWlK/wUaj8ezZk+Yp+zN3fdKle9qS9Fcv81auXuzu7jl+3JdNY1qMHTP551/WYfMkDxlZUlz09m3+7FkLAQDubh6VZjCghkeP7vdJHCAUiP7KvrAkba6fX72w0PBaVtWqZbuBnyXvz9z1w5J0Lpfn7x9gfuvHdctGj5w4csQEf78AGo128+bVNm07in39c3Mf79q9lc8XDPwsGZtz6bL5w1PHDR6cevHi2e07fmocEta6dfs9v23Lyjo+Yvh4d3ePrDPHORxO1bU/eHAvICAwLi5eLpcdPLRXU6b5YUk6AGDB/OXfzJwUE938swFDGUwmAMBoNM6Z+1VhYcHQISNEIrc7d24sWvytVlse37OP9b8Sm6pDUQtpFBpYv2HFKf7+Ad/OXkShUMJCw//KvnD9xj/jx33p7e0THdWs4jxCoUgml0ZGxmBTKs0g9vXbvjUT28H17NmnX/9uly9frH3UXF3dxGJ/AEBYWIRQKKr4Vr++g3r0SDC/3Lhhh3k3WvD2zV+XLpijFt+zz9AhIwAAwUEhJ04evnbjn9at278tLOBwOEM+H06n03vF97W49mlffWteJp1O37V7K4IgLBYrtHETOp3u7u5h/qn/unTh7r3bv+0+5uHhiR2KlJeXHTj4G4xarbBZbPOG9vb2zcn517rl5D57sn3HT48fP8BOV2Uy2/T52KxZy4ov5XLZrzt/uX7jikqlBADweXzzW2z2uxaLRqN5enpJJSUAgG5de54/f3rmrMkTv5jesGGwxVXo9fqDh/aePXeyuLiQxWIbjcbSUrm3t0/VOa9cyTYYDEOSE81TUBTlcutQl4N1OmoVMegMo9Ga+8dv3b4+c9bkpjGx33w9n+vC/W7B10aTbZ58duH899ChTCYdO34oh+MycsQEsdh/69aNr9+8tPgpOo2OGlEAQKuWbX9I+3HzT+mjxgzuFd936pez6PT/+XWYTKZv50x9/ORBasrYJk2iLl26sHffr9UVL5dL3d09Vq/cXHEijV6Hfr91qJQPUcOD0zt3ZojF/mlL0rFfJIdt4ZDoA1cBADh67IBcLtuwbjvW5Hh5+VQXtYpatWzbIrb1gYO/bdy0xtvbd1jyqIrv/vvvrZu3rs35djF2HpP/5lUNJfH5gtJSube3b50d1a9uXVezDpvNkcmkRqPlP3eFsjQ4KATLmU6nKysvM8/JZDCxnV3NsHRKJCU1zKNUlopEruZdm0JZ+t5uA7CrFVQq9bMBQz08PJ8+fQQAYDCY5eVlBoMBWwh2CGteJnb4b65KKv1vCPlmzVqiKHr02O/mKeXldetCoDO0atFRzU6dPrp6TVpkRAyfL2jbtmPFd2NiYrOyjp08dUTAF2Ye2K1SKV/kPcOuhAUHNz556siGjavHjpnMYFT7HGF4RDSNRlu/cWXPHomIDkns3b/qPDExsYcO79+6bVN4ePSlSxeuXr1sNBoVitJKZxIVHTy09/Lff8Z1i5dKSySSksaNmwAAGgU31mq1CxbOnDD+qyZhkUwm85eM9b169Xv+/Ome37YBAPKe5/qJ/QEAkZFNz184vee37Xy+ILxJVFy3+GPHD27+6ce3hQUhjUJzc59kX/5j+9bf2Wz2B29g23CGVi0uLr5f34EX/zz7c8a6+w/uVnp35PAJLWLbrFu/Yu365c2btVrw3TKpTHL7zg0AwOhREzu073L69NGaL9L6if2nT5vz+vXL9RtWXrx41uI8HTt8kjJs9OEjmUuWzNEb9BvWbw8ICDx0eF8NixWL/fU63abNa06cPJyUNHjQwGEAgK5dPx34WfKjR/df5D3z9PSaO2fJ09xHC77/5ubNq6tX/dS6dfuDh/ZiHx83dkrTmNiduzL27NmWX/CawWCsWLYhoVe/CxeyVq9Ju3X7WmLvAfS6dKxmx+5hjmwuCIkV+TeCHXaQg15n2r/y+fhlQXZafh1KvQNduZK95Ie5Ft9av3Zb/foNCK/ICcGoAexI6+ef9lh8y9PDi/BynBOMGsCGjfL1ETu6CifnDKcFECnAqEEEgVGDCAKjBhEERg0iCIwaRBAYNYggMGoQQWDUIILAqEEEsWPUBO4MKhUODE8aJqPJO8CON7fZMWocLrXkDRGdD0A2ISnQ2nX5doxa/TAXpYRkT2B/zEpea4OiuPZbvh2j5tuA4y5m/n202H6rgGzl4bXS0mIkqkO1t6d/OLuPB3rrgrzgudavEdfTj01nwrOQusVkMkkKkNISRJqv7TvBz67rsnvUAACvHmse31CXqVB5kTPsT1EUNRqNNTz2QiKefmwK1RQY7tKkldDe6yIiak7m8OHD9+7dmzdvnqMLIRm4R4MIAqMGEQRGDTc2m+3u7u7oKsgHRg03rVYrldqmL6OPCowabiwWSyi0+/ma84FRww1BEIVC4egqyAdGDTc2m+3q6uroKsgHRg03rVYrl8sdXQX5wKjhBo/VrAOjhhs8VrMOjBpEEBg13Fgslkhkx5ttnBWMGm4IgpSWljq6CvKBUYMIAqOGG4VCqVN9zJIFjBpuJpMJ6+wdwgVGDTcqlcpkMh1dBfnAqOFmNBpJNxZnXQCjBhEERg03JpPJ49WhEenIAkYNN51Op1arHV0F+cCoQQSBUcONyWTCOzusAKOGm06ng3d2WAFGDSIIjBpu8OE868Co4QYfzrMOjBpEEBg13OCzBdaBUcMNPltgHRg13Gg0GovFcnQV5AOjhhuKoggCu5PGDUYNIgiMGm4sFgt2pGAFGDXcEASBHSlYAUYNN/htgXVg1HCD3xZYB0YNN9jplXVg1HCDnV5ZB0YNN3isZh04REZtpaSkmEwmFEUVCoVOp/Px8UFRVKfT/f77744ujRxghwC1JRAIrly5Yn6J7UODgoIcWhSZwB1obY0YMYLP51ecwmQyk5KSHFcRycCo1Vbz5s0jIiIqHm8EBAT07dvXoUWRCYwaDqmpqQKBAPs3i8Xq06cPvMWj9mDUcIiNjY2KisL+7efn169fP0dXRCYwavikpKS4ubnRaLSEhAQ2m+3ocsikVmegBr2xXG20fzEkENIwOqpJqzdv3vTqMUAlh72sAQAAnUHh8Gjvne0919UeXlPevaSQFepqsyzo48QV0tWlhrBW/NY9a7qyXVPUrp2RSQr0MZ3c+G7OMHg0ZD8ahf7VI83b52WJ43wpFIrFeaqN2tXTMqXU0DrBy85FQs7j2b/KF/fVfSeILb5r+bRAXqyT5CMwZxAuQdECV2/W01sqi+9ajpokHzGZLDeDEFQDNpf29oXW4luWo6ZWoJ714Jk8hJu7mKlDLF+ssHyxQ48Y9ZajCUE1MRooKpnla0DwEi5EEBg1iCAwahBBYNQggsCoQQSBUYMIAqMGEQRGDSIIjBpEEBg1iCAwahBBHBa13NwnU6aO7tmr/Yyvv1AoSrt0jT1y9IMeEy8sfPu2sMB2BdYWiqL37t0hYEW4ttKDhzkVe1E1GAzJKf02bU63Z4Hv4Zio6fX6ud9NM5lM879bNmL4+A9fYH7BmyHJiY8fP7BFdfisWLVodXoa8eutwemsYxMnDddqy81TKBQKny9w7HM3dulIwWQyVXfXL+bFy+dFRYXz5qSFh0dhf68fuEbUYHBU5yO6Grtgfu+msIeqvULTaLRNG3YQXEYlNovaiFEDGwQGBQYGHTy0F0G0mftO83i823du/JKx/tmzJ66ubk1jWoweNdHd3ePXnRnbtm8GAEyaMlIgEB45dL7q0t4WFmzcuPrmratMJiukUejIkV+ENm6CvXXv3p0dv/784OE9AEB0dPMRw8fz+YLUEQMAAN8vnPU9AD16JMz6ZkENpRoMhm3bN2edOa5QlNav32B46rj27ToDAH4/sOfCH2c+GzB0y5YNUpmkUaPQGdPmBgQE1rCopcsX/HHxLACgS9dYAMCe3Ud9fcRVN0VeXu7OXRn3cu4AAEIbh48fP7VxSBgA4Gnu48lTRi5NW/tzxrpnz554e/uOGzOlXbtOAIDXr1+uSf/h4aMcPl/QulX7qV/OqrTq4uKiLds2Xr16WaNR16tXf8jnI7p1/RRr0tJ/XAoA6JvUDQAw85v50dHNhwxNBAAkDx05auQXtt0CtWfLHej16/88enw/bfGaRQtX8Xi8m7eufTNzUmD9hjOmzxs4IPnu3VvTZozXarVdOscNTx0HABg7ZvLsWQurLkcqlUyeMlKpUkyaOGPc2Cl6vf7LqaPz8p4BAK7fuPLV9HEqlXL8uKljx0wxoihqMLi7ecz5djEAYMTw8WvTM5KHjKy5zpWrFu/bvzOhV7853y728RHP+27G3bu3sbcePszZv3/n9OlzF36/sqS46Idl82teVPKQkc2atvD1Ea9Nz1ibnuHu5mFxUxQWFiA6ZFjy6NSUsYWFBbNmT9Fq390PiCDI94tmDeg/JH31zz7evovT5mBt/IpVi57n5U78YvqA/kNKJMVUauXflAE1PHp0v0/igAnjpgoEwiVpcx8+ug8AaNWy3cDPkgEAPyxJX5ue0aplO1eR26KFK+n0/5oVG26B2rPlDpRGp8+bk8bhcLCX69av6J2QNGXyN9jL2NjWqSMGXL/xT4f2XbD9ZnRUsyZNIqsuZ+euDFeR26oVm7CtE9ctPjml7/GThyZPnLF+w0ofH/G6tVuZTCYAoG+fz7CPhDQKBQAEBARGRsbUXOSrVy+yzhxPGTYai3unjl2TU/pt3/HT6lWbsRmWLF7j5uYOAEhKGrxx0xqFUiEUVDvMj79/gFAoksmlldZbaVN069YzLi4e+3fjxk2mTR9/L+dOi9jW2JTJk77+pEt3AMDo0ZPGjU/+9+6tjh0+KSwsCGkUmtCrHwAAi04lYl+/7Vszsb1zz559+vXvdvnyxbDQcFdXN7HYHwAQFhYhFIqwmdu362zej9t2C9SeLaMWFhZh3riFhW9fvszLz399/MShivMUFxe9dzlXr14uLimKT+hgnqLX60uKi94WFrx69WL0qIlYzqzz791bAID27btgLykUSovY1mfPnTTPwGa/+xG8vX0BAFJJiRUbuuKmwNZyKfuP/Zm7Xr7Mc3FxAQDIZf/1psv53zVKJCXYH9ie37avXbd8WPJoV1c3i2vJffZk+46fsJMhFEVlslr10EvMFqjKllEzbzIAgFwuBQCkpozt2OGTivO4/f8upgYyubRNmw5jR0+uOJHL5RUXFwIAvDy9P6RIjUYNAHAV/ffLEwiEZWVlGo2m0pwMOgMAgBpRK9ZScVMAALDD0/5Jn48dPVkqk3y/cJbRZOEGfGyNRiMKABg9aqKrq9uu3VtPnT46dsyUfn0HVpr51u3rM2dNbhoT+83X87ku3O8WfG1xmVURswWqsldXfjweHwCAIForDir5fIFCUVr1g9g2ksk/qHdtDw8vAIBSqfDw8MSmyGRSOp3+IRcCaj75RRBkz2/besX3nTRxei3bdayxGdB/SM9P+6xJT1u7bnlwUEilDbJzZ4ZY7J+2JB07zKgU7hqqsscWqA17XVfz9w/w9vY5dfpoefm7qzsGg0Gv11ucmU5nAABUKiX2slmzljk5/z5+8tA8A7aQevXqe3p6ZZ05bjC8e1DCZDIZjUYAAIvFxpr69xYWFhZBoVCuXM3GXup0uitXs8PDo2g0K3uKYLM5MpkUK8MirbYcQZCQkDDspUJZCgCoYX4MdsGCy+UOHz4eAPDk6aNKW0mhLA0OCsFyptPpysrLzMvEYiepZmvYfAvUkr1aNQqFMvGL6d/N/3ri5OGJvQcYUTTrzPG4uPgB/YdUnZnL5fqJ/fdn7hIKRb0TklJTxl65kv31NxMHfpbs6up27drfqBFdvHAVhUIZO2bKkrS5EycN79GjN5VKPXP2RL8+A+Pi4r28vMW+fvt/38XmcJRKRVK/wdX1fOYn9u/RPWH7jp9QFBWL/U+cOCSTSb+dvcjqnzQ6qtmp00dXr0mLjIjh8wVt23asNINQKGrYMPjgob1ubu4atXrHrz9TqdTnz3NrXuyChTN5XF5s89ZYJhqHhFXaSjExsVlZx06eOiLgCzMP7FaplC/ynmGX8cIjomk02vqNK3v2SER0SGLv/nbdArVkx28LOrTv8sOSdAadsWHjql93ZXh7+0ZFNatu5jlzlvj7B2SdOY5ti/Vrt4aHR+3es3XDxlWlCnm3rj2x2bp1/XTRwpUmk2nT5jW7dm8RiVz9/AOwZM+dm+biwl2/YeXprGNyuayGwqZ+OSux94BDh/ctXTZfrValLV7TrGkLq3/MuLj4fn0HXvzz7M8Z6+4/uGtxnnlz0jhszsJFs/dl7pww4athyaOyso5V18ZjwkIjHjzMWZ2e9uTpo+nT5kRERFfaSiOHT2gR22bd+hVr1y9v3qzVgu+WSWWS23duYBtw+rQ5r1+/XL9h5cWLZ+29BWrJcp8d17JkOi2I7mz5xAeCqvP2efn9v2X9JvpVfcs5e/j+JWP90WMWvpYW8IW7dx3Bu7QpU0fn5VnY37Vt22n2zO+trfGj45xRGzhwWEKChb63qRRrDhi+m/uD3mBhZ1f1pA+qgXNGTSgQ2uSqI8Z8UQD6EPDWSIggMGoQQWDUIILAqEEEgVGDCAKjBhEERg0iCIwaRBAYNYggMGoQQSx/McVkU4wAjlsA4UalAYG75WGiLLdqfFdGyctyi29BUA0k+Vrm/jqsAAAW9ElEQVQW23KoLE/1qsci/JFsyBmUa1BxkOVnFKpt1fyC2X8dKLRzYZBTuf+3vFylbxjJs/huTYM03v9H8fSOOrqTu6s3k0aHJxBQtWSFyOvH6jKVofvQah+dfM/Qs3n3NXf+LC3M09LocIf6jtFkAsBk3V2WTonvSgcANGkliO4kqmG290TNDCmHA2q/c+LEiQcPHnz99deOLqSuYDApVNr7W6La3oXL4sA/4neodNRE0cENghfcXhBBYNRwY7FYQqHNHlz4eMCo4YYgiEKhcHQV5AOjhhubzXZ3d3d0FeQDo4abVquVSj+oN6SPE4wabiwWC7ZqVoBRww1BENiqWQFGDTcqlfohPaR+tGDUcDMajTqdztFVkA+MGkQQGDXcWCyWmxvseQ43GDXcEASRyWrqlRKyCEYNIgiMGm5MJpPP5zu6CvKBUcNNp9OpVCpHV0E+MGoQQWDUcKPRaNUNigDVAEYNNxRFq47tCr0XjBpuxI9a7Bxg1HBz1MjdZAejBhEERg03eFpgHRg13OBpgXVg1CCCwKjhBh/Osw6MGm7w4TzrwKhBBIFRww0+B2odGDXc4HOg1oFRgwgCo4YbjUaDD+dZAUYNNxRF4cN5VoBRww2eFlgHRg03eFpgHRg13JhMJo9nub90qAYwarjpdDq1Wu3oKsgHRg03BoPB5XIdXQX5wKjhptfrNRqNo6sgHxg13OAZqHVg1HCDZ6DWqe1oLFBKSsr9+/exJ6ZMJhP2f39//yNHjji6NHKArVptpaSkcLlc7Mk87P9UKjUuLs7RdZEGjFptdevWLTg4uOKUgICAQYMGOa4ikoFRwyElJaXird6dO3f29PR0aEVkAqOGQ+fOnRs0aID9OzAwEDZpuMCo4TN06FCsYevUqZOXl5ejyyETGDV8unTpEhgY6OfnB5s0vKy82KGU6q+flRe+0OoRo077cY1KixqNJpOJTqM5uhCiiTyZLgJaZHtB/VBrvpezJmpFL7WnthfG9vAQujO4Qga8MPeR0CFGaYH2+b+qBhEuke1wPwmLO2ovH5VdOSGNH10P75ogp5F9uMjNm9HqU3w96uM7VjMaTTfOyD4d4Y+zNsiptO/rLSnQFb/W4voUvqgVvdIaDKA2Y8JDzo3NpeU/s2fUSksMfkEuOKuCnJBXAKdMacD1EXxRMyBGbRmKsyrICaEGk1qBLwnwuhpEEBg1iCAwahBBYNQggsCoQQSBUYMIAqMGEQRGDSIIjBpEEBg1iCAwahBBYNQggtg9as+f5yb26ZJ9+aK9V2RvarX6ydNHBKxIoSjt0jX2yNHfazPzg4c5FQe8MhgMySn9Nm1Ot2eBVrJ71Oh0Oo/Hp9Po9l6RvY0eO/jUqbrVZ8LprGMTJw3XasvNUygUCp8vYLPZDq3LMrsnICAgcM/uo3ZaONZ3hp0WXknNXS0TWYlZ1QH8aDTapg07CC6jluwbtfMXshYvmQMAWLF8Q2zzVk9zH0/9asy8OWm/bFn/6tULby+foUNHymTSo8d+V6tVTZu2mDFtrkjkCgDo3adzaOPwcm15bu5joVDUo3tCyrAxdDpdoSjtm9Rt/Lgvn+Y+vnz5YqNGoWvTMwwGw7btm7POHFcoSuvXbzA8dVz7dp0RBPlsUM9WLdvO+XYxVsydOze/mj7uhyXprVu3f1tYsHHj6pu3rjKZrJBGoSNHfhHauEkNP8jgIQlyuezwkczDRzK9vX327jkOABgxamCDwKDAwKCDh/YiiDZz3+m8vNyduzLu5dwBAIQ2Dh8/fmrjkDAAwO8H9lz448xnA4Zu2bJBKpM0ahQ6Y9rcgIBAAMCVK9k/Z6wrKHjj4yNO7D0gqV/lZ/6Ki4u2bNt49epljUZdr179IZ+P6Nb1U6xJS/9xKQCgb1I3AMDMb+ZHRzcfMjQRAJA8dOSokV8AAKRSyabNa65eu2wwGCIjYsaPm9qwYXDN9diPfXegUZFNx46ZXHFKWVlZ+tqlY0ZNWrZ0HZPFWr5i4dVrl+fNSZv21Zxbt65t2LTaPOer1y8G9B+ycvnGbl177t6zbWOFt3bt2uLj7btq5eaJX0wHAKxctXjf/p0JvfrN+Xaxj4943ncz7t69zWKxusf1yr58saysDPvU2XMnvb19WrZsK5VKJk8ZqVQpJk2cMW7sFL1e/+XU0Xl5z2r4QRbMX87nCzq077I2PWPB/OXm6dev//Po8f20xWsWLVzF4/EKCwsQHTIseXRqytjCwoJZs6dote/uin74MGf//p3Tp89d+P3KkuKiH5bNx7bGgoUzmQzm9Glz27bpKJWWVF21ATU8enS/T+KACeOmCgTCJWlzHz66DwBo1bLdwM+SAQA/LElfm57RqmU7V5HbooUr6fR3zYdWq502Y/zNW9fGjpkybeq3EmnJtBnjVWpVDfXYlX1bNU9Pr+ioZpUmjh83tXXr9gCAgZ8lL1v+/Vdfzm7QICgCRN+8efXqtcvm2Tp3iuvcqRsAICIiWqlUHDt+MDV1HPZWkyaRo0dNxP796tWLrDPHU4aNHp46DgDQqWPX5JR+23f8tHrV5t4JSQcO/nbp0oUePRIQBPnr0vlBA1OoVOrOXRmuIrdVKzZhv5W4bvHJKX2Pnzw0eeKM6n6Q0MZN6HS6u7tHZGRMxek0On3enDQOh4O97NatZ1xcPPbvxo2bTJs+/l7OnRaxrbEpSxavcXNzBwAkJQ3euGmNQqlQq1UIgnTo8Elct57VrVrs67d9aya2d+7Zs0+//t0uX74YFhru6uomFvsDAMLCIoRCETZz+3adzfvxs+dOvnr1YtXKTc2atgAAREY2HZKcePDg3tSUMdXVIxTYcfBJBxyts5jvRqNmMJgAAMb/j2zi6emlUJRa/EjLlm2Pnzj09OmjRsGNAQDNmrU0v/Xv3VsAgPbtu2AvKRRKi9jWZ8+dBADUr98gMjLm3PlTPXokXP77T61WG9+zDwDg6tXLxSVF8QkdzAvR6/UlxUVW/CxhYRHmnGFrv5T9x/7MXS9f5rm4uAAA5LL/Ov1js9/N6e3tCwCQSkoaNAgKD4/atXsLm83pnZBU3SAvuc+ebN/x0+PHD7ABOmSyWnUk+O+/N3lcHpYzAICPj29AQODjJw9qqMfZolYdrHM8i2/xeHwAQHn5u12heRsBADQaNQDAVfTfM4kCgbCsrEyj0XC53N69kpYuXyCVSs6eO9m+XWfsj1gml7Zp02Hs6P/Zs3O51vQPz6lQCQDg150Z27Zv7p/0+djRk6UyyfcLZxlNFh79Z9AZAADUiFIolKVpazO2rN/8U3rm77tmz1wYHV15J3Dr9vWZsyY3jYn95uv5XBfudwu+trjMqtQatVDkWnGKQCCUSizso8311O6HthI5LuFKSooBAJ6e3lXf8vDwAgAolf+NBSuTSel0OnbC37FjVy6Xd/DQ3uvX/0lMHIDNwOcLFIrSgIDAiv+5u3u8t4yaH89GEGTPb9t6xfedNHF6ZGRMk7DI2vxoPB5v6pezdmw/wOXy5s6bZj6yNNu5M0Ms9k9bkt6yRZvw8KhK4a6hKk8Pr4qbBdsy2B+tQ5AgaiaT6dTpo3wev35Ag6rvhoVFUCiUK1ezsZc6ne7K1ezw8CgajYYNfh0XF//b3h1+fvWaxsRi8zRr1jIn59/HTx6aF1JeXl51yZVw2BypVFLDDFptOYIgISFh2EuFshQAYDS+pwXCLliIff2S+g1Wa9SFhQV0OgMAoFIpzcsJDgrBDit1Ol1ZeZl5mVjsJJYaKgBAeHiUSqV8+DAHe/ns2dP8/NeVjjWJVId2oJX8cfGMu7sHi8X+889zt+/cGDd2CofD0ekqX0nyE/v36J6wfcdPKIqKxf4nThySyaTfzl5knqF3r6SDB/f2TkgyT0lNGXvlSvbX30wc+Fmyq6vbtWt/o0Z08cJVNdcTGdn0/IXTe37bzucLwptEYVcNKhIKRQ0bBh88tNfNzV2jVu/49Wcqlfr8eW4Ny9Tr9akj+nfuFNcgMOjIkUwelycW+7PZbD+x//7MXUKhqHdCUkxMbFbWsZOnjgj4wswDu1Uq5Yu8Z9hlvPCIaBqNtn7jyp49EhEdkti7f8WFY2fuCxbOHJY8mkql7tyZIRK59kn8rBbb3i7qbqvm4eGVdeb4ho2riosLx4/7cvCglOrmnPrlrMTeAw4d3rd02Xy1WpW2eI35WBgAEBjYMLZ5q+7dE8xT/MT+69duDQ+P2r1n64aNq0oV8m5dqz0BNBs3dkrTmNiduzL27NmWX/Da4jzz5qRx2JyFi2bvy9w5YcJXw5JHZWUd0+v11S2zXFveNKbFufOn0tcupTMYaUvSsf3+nDlL/P0Dss4cBwCMHD6hRWybdetXrF2/vHmzVgu+WyaVSW7fuYH9INOnzXn9+uX6DSsvXjxbaeF0On3Fsg2NQ5ps2rxm3foVAQGBP675xdUVX0cbNoSve5h72Yqi17pW8XbvlbN3n87xPftOGD/V3iuCrPPsrqroRVmPYRaOnqtTd3egxJsydXRenoX9Xdu2nWbP/N4RFTkVGLX/fDf3B73Bws6u6kkfZIU6GrVjRxxw05GHB+yu247q7mkB5GRg1CCCwKhBBIFRgwgCowYRBEYNIgiMGkQQGDWIIDBqEEHwRY1KAywOTCcEaAwK2wVneHDNzXdlSPLxDYwAOaXSQoTNxTegG76oufkwKVQ4FAsE9Dqjp5/lh26qgy9qPBFd3JB97ZTlO4yhj0Rejkot1zeMxPfgjzWDNF49LS2VoC16eDCY8Ljt42I0mp7eUuQ/LUsc54u34wgrh569e6k052+lXmcUujMNho9rQFCTyWQymajUj+7PjEqlvH1eFtle2DHJmrutrIwaAMCImlRyg7oU35hWTiA7OzsvL2/YsGGOLoRoLBeqh5hl9cetvzWSSqMIPRhCD4bVSyApVo5GTy/yC4a35uLz0e0FIEeBUcONSqVW17kGVAMYNdyMRmPN3fpBFsGo4cZisVxdXWsxI/Q/YNRwQxBELpc7ugrygVHDjclkCgQCR1dBPjBquOl0OqVS6egqyAdGDSIIjBpuNBqNxbL+ovlHC0YNNxRFqw4YAL0XjBpuLBZLJBI5ugrygVHDDUGQ0lLLPZFDNYBRgwgCo4Ybm812d3d3dBXkA6OGm1arlUprNUgFVBGMGkQQGDXcWCyWUGjHAXKcFYwabgiCKBSKWswI/Q8YNYggMGq4MRgMLpfr6CrIB0YNN71er9FoHF0F+cCoQQSBUcONRqPBx1isAKOGG4qi8DEWK8Co4QYfzrMOjBpu8OE868CoQQSBUcMNPgdqHRg13OBzoNaBUYMIAqOGG7yzwzowarjBOzusA6OGG2zVrAOjhhts1awDo4Yb3p6tIQyMGm5Wd1T9kYNRgwgCowYRBEYNNyaTyefzHV0F+cCo4abT6VQqlaOrIB/rR2P52CQmJubn51ea6ObmdvbsWQdVRDKwVaut4cOHs1gsSgUmk6lNmzaOros0YNRqKykpyc/Pr+IUX1/flJQUx1VEMjBqOHz++efmrklNJlOzZs2Cg4MdXRRpwKjhkJSUJBaLsX97e3t/hIPnfQgYNXwGDhyINWwtWrQICQlxdDlkAqOGT//+/QMCAry9vZOTkx1dC8k4+cWO/NzyotdahcSgUaB0BkUlt8FAuXK5vFxbLvYVf/ii2DyqCQVcAY3nSvf0YzaI4Drxd/nOGbWCZ+V3LilfPdRwBEyOkE2jU+ksGp1l/Ti79oPqUL0ONSAoiuhl+Rq/YJeItvxGTZ3w2whni5qsUHfxgESjNvE9eHxPFxqDZEcIypIyrbJcq9B2THIPDHOq/o6cKmp/HpLm3lF7BrkJPF0cXcsH0ap0xc9kHr6MnqleTrNHdZ6oHdlcoDMxPQOd5wlNlaSsJFeaMieAziRZ22yRk0Tt8Oa3VDZX4O1UexwAgK5M//puYcqcegwmzdG1fChn+HPZt/oNjeOEOQMAMF0YDVr6/zw7z9GF2ADpW7Xze4uVKoarvzOPBVuuQOQvpUNm1nN0IR+E3K3a0zuqUjnFuXMGAOAIWTwv/j8nJY4u5IOQO2p/HZQIfJw8ZxiBDz/nskqjsMElaEchcdTuXirlubsw2HXxwqw9eAa5/XWIxA0biaP24JraPbAujsspkb6eMa/V7btnbLtYkS9PVoIqpHrbLpYwZI1a0SuttsxEZ34sTRqGxmC8uE/WfuzJGrVndzVcN46jqyAaz8Ml91+yRo2srYKsSMfztFcfLX9fO/Dn5T0KZbGbq7hpVPfO7ZIZDFZ+weP1GWNGDVtz8szGgsInriLfXt0nRYR1xD6i1siPnFxz/9FfDDorqEFzOxXGc+doihUGvZFOtu92SdyqvX2mZdhn73nmwi8nstbHRMYN7Ds3KrzrxUu7fj/yA/aWXo/s2jenY9vBE0ZuchX57Mmcp9GUAgD0Bt1P2yfff/hnx7ZDevWYJJMX2KMwjLpUX6ZE7bd8+yFlq2YympBylM6y/Xc1CmXJ+b+2Dx2wKCriE2yKkO9x4NiyPvHTsJd9e02PiYwDAMTHfZG+KfXZi9tR4V0uX8l8W/h0bOq6kOCWAIDAepHL1w6yeW0YBoumURoE7gw7Ld9+SBk1tdIg8GDZY8lPn11DUcPu37/b/ft3/z/NBABQqIqxF0zGuwNEV5EvAECpKgEA5Dz809c7GMsZAIBKteP3lUwuA7ZqxKEzqOUqu5zzK1USAMCo5NUioVfF6e5u/oVFz/6nBhoDAGA0ogCAUkWhn29je9RTlQFBaQxS3ldEyqhxuDSD3mgymihUG290Dufddw9enoG1/xSP66rWENTntwFBXQSkvMuDrKcFHC5dj9h+P9KoYSyFQsm+ut88BdGVv/dTfr6NX+c/KC55afN6qtJpUa6AlA0EKYsGAHgHspEyPZNj4/o93Ou1bz3o0j97t+6aHh7WSaWSXL76+6hhq/3FoTV8qkuHlBt3Tm7cOr5jm8ECvsetu1m2rcoMNRg5PBqMGqECQtj3b2j47ra/ipvYc6pI6JV9JfNx7hUB3yOiSWehwKvmj3i4+49J+fF41tqsC7+IhN6RYZ2f5F61eWEAAGWxxtPfLudDBCDr/WrqUsNvK143ah/g6EIIlZ9T1Kq7IDia5+hCrEHWVo0nonsHcsoUiIuw2r/yXfvnPnr6T9XpIoF3qbKo6nQuRzh72kEbFrkhY9zbotyq0/19Q9+8fWTxIwtmnqbTq79mZkKDIsl6szFZWzUAQP6z8nN7JfWbVfvor0ot0+u1VacbDHqLv04Kheoq8rFhhQplCYpauCiDdZhl8SOuIt/qnjoueiprEEpr2d3NhhUSiaytGgDAL4jDF9JUJWX8ah7F4/Mc/FsRCjxttSiDHi0tULWc0tBWCyQeWS92YLoO9tRIlI6uggiKN6VdBtksuA5B7qgJPRgt4oT59ywceDkT6atSLzE1hOS9K5A7agCAoEheSFNOwYMSRxdiL5IXChZN36Gvh6ML+VAkPi2oKOcf1d2/1eIm77kARjrSl6UcliF+hLejC7EBJ4kaAODBVeW1M6U+oZ5sHtPRtdiA0WCUvJB7i6md+pO+PcM4T9QAANK3yPGMQoYLyyvYjU7mngeKn8mlLxVdBnmFxpL7+Kwip4oa5sEV5bUsOZXJ4Hm4CLxcyJI5k8mkLC5Tl5ShBn1INLd1PFmvn1XHCaOGycvRPLqpfvVQw+IxAAB0Jp3FZRr0deumQhqdpi/XGbCu/AyoZz1O42bcRk15DKfoeqgSp42ambxYV6ZCy5QGHWLSI0ZHl/M/6AwqnQm4AjpXQHf1Zjhx76QfRdSgOsIJG2qoboJRgwgCowYRBEYNIgiMGkQQGDWIIP8HEab7XyXQ0+0AAAAASUVORK5CYII=",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "静夜思\\n 床前明月光\\n 疑是地上霜\\n 举头望明月\\n 低头思故乡\\n\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Thoughts in the Silent Night\n",
      "Before my bed, the bright moonlight\n",
      "I suspect it is frost on the ground\n",
      "I lift my head to gaze at the bright moon\n",
      "Then lower it, thinking of my hometown\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 503 - {'error': {'message': 'An internal error has occurred. Our team has been alerted (001). (request id: 2025020616250044030479776495327) (request id: 2025020616250036121340953519554) (request id: 20250206162500343365670cyIg1cKd)', 'type': 'internal_error', 'param': '', 'code': 'yesai_api_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInternalServerError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 160\u001B[0m\n\u001B[1;32m    158\u001B[0m user_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m输入中翻译英的内容: \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    159\u001B[0m events \u001B[38;5;241m=\u001B[39m graph\u001B[38;5;241m.\u001B[39mstream({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, user_input)}, stream_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 160\u001B[0m \u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mevents\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpretty_print\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1724\u001B[0m, in \u001B[0;36mPregel.stream\u001B[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001B[0m\n\u001B[1;32m   1718\u001B[0m     \u001B[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001B[39;00m\n\u001B[1;32m   1719\u001B[0m     \u001B[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001B[39;00m\n\u001B[1;32m   1720\u001B[0m     \u001B[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001B[39;00m\n\u001B[1;32m   1721\u001B[0m     \u001B[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001B[39;00m\n\u001B[1;32m   1722\u001B[0m     \u001B[38;5;66;03m# with channel updates applied only at the transition between steps.\u001B[39;00m\n\u001B[1;32m   1723\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m loop\u001B[38;5;241m.\u001B[39mtick(input_keys\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_channels):\n\u001B[0;32m-> 1724\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtick\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1725\u001B[0m \u001B[43m            \u001B[49m\u001B[43mloop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtasks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1726\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1727\u001B[0m \u001B[43m            \u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1728\u001B[0m \u001B[43m            \u001B[49m\u001B[43mget_waiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mget_waiter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1729\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1730\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# emit output\u001B[39;49;00m\n\u001B[1;32m   1731\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01myield from\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1732\u001B[0m \u001B[38;5;66;03m# emit output\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/langgraph/pregel/runner.py:230\u001B[0m, in \u001B[0;36mPregelRunner.tick\u001B[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001B[0m\n\u001B[1;32m    228\u001B[0m t \u001B[38;5;241m=\u001B[39m tasks[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    229\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 230\u001B[0m     \u001B[43mrun_with_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    232\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    233\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfigurable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m    234\u001B[0m \u001B[43m            \u001B[49m\u001B[43mCONFIG_KEY_SEND\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[43m            \u001B[49m\u001B[43mCONFIG_KEY_CALL\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcall\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommit(t, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/langgraph/pregel/retry.py:40\u001B[0m, in \u001B[0;36mrun_with_retry\u001B[0;34m(task, retry_policy, configurable)\u001B[0m\n\u001B[1;32m     38\u001B[0m     task\u001B[38;5;241m.\u001B[39mwrites\u001B[38;5;241m.\u001B[39mclear()\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;66;03m# run the task\u001B[39;00m\n\u001B[0;32m---> 40\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ParentCommand \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     42\u001B[0m     ns: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/langgraph/utils/runnable.py:495\u001B[0m, in \u001B[0;36mRunnableSeq.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    491\u001B[0m config \u001B[38;5;241m=\u001B[39m patch_config(\n\u001B[1;32m    492\u001B[0m     config, callbacks\u001B[38;5;241m=\u001B[39mrun_manager\u001B[38;5;241m.\u001B[39mget_child(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseq:step:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    493\u001B[0m )\n\u001B[1;32m    494\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 495\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    497\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/langgraph/utils/runnable.py:259\u001B[0m, in \u001B[0;36mRunnableCallable.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    257\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m     context\u001B[38;5;241m.\u001B[39mrun(_set_config_context, config)\n\u001B[0;32m--> 259\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, Runnable) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecurse:\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "Cell \u001B[0;32mIn[10], line 98\u001B[0m, in \u001B[0;36mreflect_on_translation\u001B[0;34m(state)\u001B[0m\n\u001B[1;32m     72\u001B[0m         reflection_prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124mYour task is to carefully read a source text and a translation from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msource_lang\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget_lang\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, and then give constructive criticisms and helpful suggestions to improve the translation. \u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[1;32m     73\u001B[0m \n\u001B[1;32m     74\u001B[0m \u001B[38;5;124mThe source text and initial translation, delimited by XML tags <SOURCE_TEXT></SOURCE_TEXT> and <TRANSLATION></TRANSLATION>, are as follows:\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;124mEach suggestion should address one specific part of the translation.\u001B[39m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;124mOutput only the suggestions and nothing else.\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     94\u001B[0m     messages \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     95\u001B[0m         (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msystem\u001B[39m\u001B[38;5;124m\"\u001B[39m, system_message),\n\u001B[1;32m     96\u001B[0m         (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m\"\u001B[39m, reflection_prompt)\n\u001B[1;32m     97\u001B[0m     ]\n\u001B[0;32m---> 98\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m]}\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:284\u001B[0m, in \u001B[0;36mBaseChatModel.invoke\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m    274\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    275\u001B[0m     \u001B[38;5;28minput\u001B[39m: LanguageModelInput,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    279\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    280\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseMessage:\n\u001B[1;32m    281\u001B[0m     config \u001B[38;5;241m=\u001B[39m ensure_config(config)\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[1;32m    283\u001B[0m         ChatGeneration,\n\u001B[0;32m--> 284\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m            \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcallbacks\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    288\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtags\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    289\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    291\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    293\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    294\u001B[0m     )\u001B[38;5;241m.\u001B[39mmessage\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:860\u001B[0m, in \u001B[0;36mBaseChatModel.generate_prompt\u001B[0;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    852\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[1;32m    853\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    854\u001B[0m     prompts: \u001B[38;5;28mlist\u001B[39m[PromptValue],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    857\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    858\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[1;32m    859\u001B[0m     prompt_messages \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[0;32m--> 860\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:690\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[1;32m    687\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(messages):\n\u001B[1;32m    688\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    689\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 690\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    692\u001B[0m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    693\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    694\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    695\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    696\u001B[0m         )\n\u001B[1;32m    697\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    698\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:925\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    923\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    924\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 925\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    927\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    928\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    929\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:790\u001B[0m, in \u001B[0;36mBaseChatOpenAI._generate\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    788\u001B[0m     generation_info \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheaders\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mdict\u001B[39m(raw_response\u001B[38;5;241m.\u001B[39mheaders)}\n\u001B[1;32m    789\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 790\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpayload\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_chat_result(response, generation_info)\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:279\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m--> 279\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py:863\u001B[0m, in \u001B[0;36mCompletions.create\u001B[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    821\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    822\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    823\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    860\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[1;32m    861\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[1;32m    862\u001B[0m     validate_response_format(response_format)\n\u001B[0;32m--> 863\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/chat/completions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43maudio\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrequency_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    871\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunction_call\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    872\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunctions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    873\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogit_bias\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_completion_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodalities\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodalities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mparallel_tool_calls\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    882\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpresence_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    883\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreasoning_effort\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_effort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    884\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    885\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    886\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mservice_tier\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    887\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    888\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    889\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    890\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    891\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    892\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_choice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    894\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_logprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    895\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    896\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    897\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    898\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    899\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    900\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    901\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m    902\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    903\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    904\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    905\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    906\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/openai/_base_client.py:1283\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1270\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1271\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1278\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1279\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1280\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1281\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1282\u001B[0m     )\n\u001B[0;32m-> 1283\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/openai/_base_client.py:960\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    957\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    958\u001B[0m     retries_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 960\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    961\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    962\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    963\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    964\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    965\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries_taken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    966\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/openai/_base_client.py:1049\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1047\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m remaining_retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[1;32m   1048\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m-> 1049\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1050\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1051\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1052\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries_taken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1053\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresponse_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1054\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1055\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1056\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1058\u001B[0m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[1;32m   1059\u001B[0m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[1;32m   1060\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/openai/_base_client.py:1098\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[1;32m   1095\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[1;32m   1096\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[0;32m-> 1098\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1099\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1100\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1101\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries_taken\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1102\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1104\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/openai/_base_client.py:1049\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1047\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m remaining_retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[1;32m   1048\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m-> 1049\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retry_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1050\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1051\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1052\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries_taken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1053\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresponse_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1054\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1055\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1056\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1058\u001B[0m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[1;32m   1059\u001B[0m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[1;32m   1060\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/openai/_base_client.py:1098\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[1;32m   1095\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[1;32m   1096\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[0;32m-> 1098\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1099\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1100\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1101\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries_taken\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1102\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1104\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/egg/.venv/lib/python3.12/site-packages/openai/_base_client.py:1064\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1061\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1063\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1064\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1066\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[1;32m   1067\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   1068\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1072\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[1;32m   1073\u001B[0m )\n",
      "\u001B[0;31mInternalServerError\u001B[0m: Error code: 503 - {'error': {'message': 'An internal error has occurred. Our team has been alerted (001). (request id: 2025020616250044030479776495327) (request id: 2025020616250036121340953519554) (request id: 20250206162500343365670cyIg1cKd)', 'type': 'internal_error', 'param': '', 'code': 'yesai_api_error'}}",
      "\u001B[0mDuring task with name 'reflect_on_translation' and id '5dc4eb8c-d5fa-e807-2965-d4fa68bfa17a'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# langgraph chat\n",
    "from typing import TypedDict, Annotated, Dict, List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "# 加载 .env 文件\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "                 openai_api_base=os.getenv(\"OPENAI_API_BASE\"))\n",
    "\n",
    "source_lang = \"Chinese\"\n",
    "target_lang = \"English\"\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "def initial_translate(state: State):\n",
    "    source_text = state[\"messages\"][-1].content\n",
    "    system_prompt = f\"You are an expert linguist, specializing in translation from {source_lang} to {target_lang}.\"\n",
    "    translation_prompt = f\"\"\"This is an {source_lang} to {target_lang} translation, please provide the {target_lang} translation for this text. \\\n",
    "Do not provide any explanations or text apart from the translation.\n",
    "{source_lang}: {source_text}\n",
    "\n",
    "{target_lang}:\"\"\"\n",
    "    messages = [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", translation_prompt)\n",
    "    ]\n",
    "    return {\"messages\": [llm.invoke(messages)]}\n",
    "\n",
    "\n",
    "def reflect_on_translation(state: State):\n",
    "    country = \"America\"\n",
    "    source_text = state[\"messages\"][-2].content\n",
    "    translation_1 = state[\"messages\"][-1].content\n",
    "    system_message = f\"You are an expert linguist specializing in translation from {source_lang} to {target_lang}. \\\n",
    "You will be provided with a source text and its translation and your goal is to improve the translation.\"\n",
    "\n",
    "    if country != \"\":\n",
    "        reflection_prompt = f\"\"\"Your task is to carefully read a source text and a translation from {source_lang} to {target_lang}, and then give constructive criticism and helpful suggestions to improve the translation. \\\n",
    "The final style and tone of the translation should match the style of {target_lang} colloquially spoken in {country}.\n",
    "\n",
    "The source text and initial translation, delimited by XML tags <SOURCE_TEXT></SOURCE_TEXT> and <TRANSLATION></TRANSLATION>, are as follows:\n",
    "\n",
    "<SOURCE_TEXT>\n",
    "{source_text}\n",
    "</SOURCE_TEXT>\n",
    "\n",
    "<TRANSLATION>\n",
    "{translation_1}\n",
    "</TRANSLATION>\n",
    "\n",
    "When writing suggestions, pay attention to whether there are ways to improve the translation's \\n\\\n",
    "(i) accuracy (by correcting errors of addition, mistranslation, omission, or untranslated text),\\n\\\n",
    "(ii) fluency (by applying {target_lang} grammar, spelling and punctuation rules, and ensuring there are no unnecessary repetitions),\\n\\\n",
    "(iii) style (by ensuring the translations reflect the style of the source text and take into account any cultural context),\\n\\\n",
    "(iv) terminology (by ensuring terminology use is consistent and reflects the source text domain; and by only ensuring you use equivalent idioms {target_lang}).\\n\\\n",
    "\n",
    "Write a list of specific, helpful and constructive suggestions for improving the translation.\n",
    "Each suggestion should address one specific part of the translation.\n",
    "Output only the suggestions and nothing else.\"\"\"\n",
    "\n",
    "    else:\n",
    "        reflection_prompt = f\"\"\"Your task is to carefully read a source text and a translation from {source_lang} to {target_lang}, and then give constructive criticisms and helpful suggestions to improve the translation. \\\n",
    "\n",
    "The source text and initial translation, delimited by XML tags <SOURCE_TEXT></SOURCE_TEXT> and <TRANSLATION></TRANSLATION>, are as follows:\n",
    "\n",
    "<SOURCE_TEXT>\n",
    "{source_text}\n",
    "</SOURCE_TEXT>\n",
    "\n",
    "<TRANSLATION>\n",
    "{translation_1}\n",
    "</TRANSLATION>\n",
    "\n",
    "When writing suggestions, pay attention to whether there are ways to improve the translation's \\n\\\n",
    "(i) accuracy (by correcting errors of addition, mistranslation, omission, or untranslated text),\\n\\\n",
    "(ii) fluency (by applying {target_lang} grammar, spelling and punctuation rules, and ensuring there are no unnecessary repetitions),\\n\\\n",
    "(iii) style (by ensuring the translations reflect the style of the source text and take into account any cultural context),\\n\\\n",
    "(iv) terminology (by ensuring terminology use is consistent and reflects the source text domain; and by only ensuring you use equivalent idioms {target_lang}).\\n\\\n",
    "\n",
    "Write a list of specific, helpful and constructive suggestions for improving the translation.\n",
    "Each suggestion should address one specific part of the translation.\n",
    "Output only the suggestions and nothing else.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        (\"system\", system_message),\n",
    "        (\"human\", reflection_prompt)\n",
    "    ]\n",
    "    return {\"messages\": [llm.invoke(messages)]}\n",
    "\n",
    "\n",
    "def improve_translation(state: State):\n",
    "    source_text = state[\"messages\"][-3].content\n",
    "    translation_1 = state[\"messages\"][-2].content\n",
    "    reflection = state[\"messages\"][-1].content\n",
    "\n",
    "    system_message = f\"You are an expert linguist, specializing in translation editing from {source_lang} to {target_lang}.\"\n",
    "\n",
    "    prompt = f\"\"\"Your task is to carefully read, then edit, a translation from {source_lang} to {target_lang}, taking into\n",
    "account a list of expert suggestions and constructive criticisms.\n",
    "\n",
    "The source text, the initial translation, and the expert linguist suggestions are delimited by XML tags <SOURCE_TEXT></SOURCE_TEXT>, <TRANSLATION></TRANSLATION> and <EXPERT_SUGGESTIONS></EXPERT_SUGGESTIONS> \\\n",
    "as follows:\n",
    "\n",
    "<SOURCE_TEXT>\n",
    "{source_text}\n",
    "</SOURCE_TEXT>\n",
    "\n",
    "<TRANSLATION>\n",
    "{translation_1}\n",
    "</TRANSLATION>\n",
    "\n",
    "<EXPERT_SUGGESTIONS>\n",
    "{reflection}\n",
    "</EXPERT_SUGGESTIONS>\n",
    "\n",
    "Please take into account the expert suggestions when editing the translation. Edit the translation by ensuring:\n",
    "\n",
    "(i) accuracy (by correcting errors of addition, mistranslation, omission, or untranslated text),\n",
    "(ii) fluency (by applying {target_lang} grammar, spelling and punctuation rules and ensuring there are no unnecessary repetitions), \\\n",
    "(iii) style (by ensuring the translations reflect the style of the source text)\n",
    "(iv) terminology (inappropriate for context, inconsistent use), or\n",
    "(v) other errors.\n",
    "\n",
    "Output only the new translation and nothing else.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        (\"system\", system_message),\n",
    "        (\"human\", prompt)\n",
    "    ]\n",
    "    return {\"messages\": [llm.invoke(messages)]}\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(initial_translate)\n",
    "workflow.add_node(reflect_on_translation)\n",
    "workflow.add_node(improve_translation)\n",
    "\n",
    "# 定义有向无环图\n",
    "workflow.set_entry_point(\"initial_translate\")\n",
    "workflow.add_edge(\"initial_translate\", \"reflect_on_translation\")\n",
    "workflow.add_edge(\"reflect_on_translation\", \"improve_translation\")\n",
    "workflow.add_edge(\"improve_translation\", END)\n",
    "graph = workflow.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "user_input = input(\"输入中翻译英的内容: \")\n",
    "events = graph.stream({\"messages\": (\"user\", user_input)}, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-06T08:25:00.642940Z",
     "start_time": "2025-02-06T08:24:42.770201Z"
    }
   },
   "id": "ef7e4d35acff52da",
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
